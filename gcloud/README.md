# Overview

This playbook is designed for deployment automation of a clone of "POA Network".

Namely, the following operations are performed:

- A random account is generated for the Master of Ceremony (MoC)
  
- The bytecode of the Network Consensus Contract is prepared

- Based on the prior data, the genesis JSON file is prepared

- The netstat node is started

- Several (configurable number) bootnodes are started, `bootnodes.txt` is exchanged between them

- Additionally, some more bootnodes can be started behind a Gateway, forming a publicly accessible RPC endpoint for the network. This endpoint is available over `http`, but the user may later assign it a DNS name, generate valid SSL certificates and upload them to the Gateway config, turning this endpoint into `https`.

- The explorer node is started

- The MoC node is started

- The ceremony is performed on the MoC node, i.e. other consensus contracts are deployed to the network

- Several (configurable number) initial keys are generated

- A subset (or all) of the initial keys are converted into (mining + voting + payout) keys

- For a subset (or for all) of converted keys, validator nodes are started

- Simple tests can be run against the network: (1) check that txs are getting mined (2) check that all validators mine blocks (only makes sense if validator nodes were started for all mining keys)

- Artifacts (`spec.json`, `bootnodes.txt`, `contracts.json`, ...) are stored on the MoC node

- A `hosts` file is generated on the user's machine containing IP addresses of all nodes and their respective roles

Most of the work is done by `ansible`, but to bring up the infrastructure, ansible calls `terraform`.

# Usage

## Step 1: Install prerequisites

To run these scripts you need to install:
1. [Ansible >=2.6.3](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html)
2. [Terraform >=0.11.8](https://www.terraform.io/intro/getting-started/install.html)

## Step 2: Playbook configuration

Configuration options are stored in `group_vars/all.yml`. An example is given in `group_vars/all.yml.example` so you need to copy it and use a template
```bash
cd gcloud
cp group_vars/all.yml.example group_vars/all.yml
```

Notes about some configuration parameters:

* `spec_address` - by default, ansible generates the genesis JSON file based on the following template: `roles/moc-preconf/templates/spec.json.j2`. If you want to adjust parameters of the genesis, you should create your own copy of that template and update it `cp roles/moc-preconf/templates/spec.json.j2 my-spec.json.j2`. For example, to change block time, you can update value in `engine.authorityRound.params.stepDuration`. Then you should set `SPEC_ADDRESS: my-spec.json.j2`. You should NOT change values enclosed in double curly brackets `"{{ ... }}"`, since they are automatically filled by ansible.

* `bootnode_balanced_count` - this is the number of ADDITIONAL bootnodes that will be put into the RPC endpoint. So the total number of bootnodes is `bootnode_count+bootnode_balanced_count`.

* `initial_key_count` - the number of initial keys generated by MoC during ceremony. Max = 12
* `initial_key_convert_count` - the number of (mining + voting + payout) keys generated from the initial keys. Should be `<= initial_key_count`
* `validator_count` - the number of validator nodes to run. Should be `<= initial_key_convert_count`.
* `terraform_location` - path to the `terraform` binary. Default value is for typical linux installation. To find correct path on your system, run `which terraform`.
* `tf_prefix` - all resources created by terraform will be prefixed with the value of this variable. Can contain uppercase and lowercase letters, numbers, dashes and underscores. No other symbols allowed!
* `pub_key_store` - path to your public key. This key will be copied to all created nodes of the network
* `ansible_user` - this is the user to connect to the nodes with.
* `ansible_python_interpreter`, `ansible_pip` - same as for `terraform_location`, default values are for Linux, use `which` to find correct paths on your system.
* `backend` - deployment-terraform scripts support both local and remote state storage. While `backend: false` will keep the state locally, `backend: true` will automatically create a storage account at Azure and save terraform state to the blob inside it. It is a best practice to keep backend remotely, since it is much safer.

It is also possible to use `group_vars/all.yml` to overwrite options used by ansible playbooks during nodes deployment. For example, if you want to use custom parity binary, you should add the following two configuration parameters to `group_vars/all.yml`:
```yaml
PARITY_BIN_LOC: "https://..."
PARITY_BIN_SHA256: "..."
```

Another example - change gas limit - you need to use custom spec json file (see above) and set hex value `genesis.gasLimit = "0x..."`, after that additionally set option for ansible playbooks in `group_vars/all.yml`
```yaml
BLK_GAS_LIMIT: "9000000" # decimal here !
```

## Step 3: Generate SSH keys

We recommend using a separate key for ansible deployment. To generate a new key run `ssh-keygen -t rsa -b 4096 -C "full-node"`
You should explicitly specify the path to your public SSH key. The Ansible script will put it on all the virtual machines in a deployment. Also, do not forget to specify the private SSH key while calling Ansible scripts via `--key-file`, otherwise the default SSH key of your system will be used.

## Step 4: Deploy

To deploy your POA network run `ansible-playbook site.yml --key-file <key_name>`.
After deployment, the script will create a file called `hosts` with the list of created resources.

```
ansible-playbook site.yml --key-file <key_name>
```
The deployment process may take more than 1 hour, depending on the number of nodes and Azure performance. After deployment, the script will create a file called `hosts` inside the `outputs/<network_name>` folder with the list of created resources.

# Clean up

When the infrastructure is no longer needed run `ansible-playbook destroy.yml -i <hosts_file>`

# Managing multiple deployments

In case you want to deploy several environments use separate configuration files (`all.yml`).

# Deploying infrastructure separately

If you want to deploy infrastructure for a network without creating the network itself you can refer to these READMEs: [building nodes](roles/terraform/files/README.md), [bringing up a balancer](roles/balancer/files/README.md), [using remote state](roles/storage-account/README.md) and [creating resource group](roles/resource-group/README.md) 

# Continuous Integration

You may want to setup a continuous integration. This repository contains [.circleci/config.yml](../.circleci/config.yml) file with a designed workflow for a [CircleCI](https://circleci.com). To make everything work properly you will need to setup environment variables. Some of them are required and the others are optional.

## Configs

Besides the azure authentication variables CI requires config and a public SSH key to be set:
`config_file` - base64 encoded version of `group_vars/all.yml` file
`pub_key` - plain text SSH public key. Make sure to set this option properly or you might not be
able to reach your deployment via SSH.

Also you will need to specify the private part of your SSH key at the SSH permissions page of
the CircleCI project configuration.

## Optional variables

`build_attr`
`tests_attr`
`destroy_attr`

These variables append to the script execution line (corresponding to the job of the workflow).
They are optional, however in some cases they may be useful. For example, you may want to specify
extra variables or a tag: `-e "backend=true" -e "network_name=PoANet" -t deploy`.
